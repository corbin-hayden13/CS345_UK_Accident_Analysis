{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All dependencies\n",
    "import sys\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import path\n",
    "from time import time\n",
    "from copy import deepcopy\n",
    "from mpl_toolkits.mplot3d import Axes3D as plt3\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "from sklearn.model_selection import train_test_split as tts, cross_validate, GridSearchCV as GSCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commonly Used Methods**\n",
    "\n",
    "The methods below are commonly used when running a variety of classification and regression models.\n",
    "\n",
    "**Culling the Accidents Data**\n",
    "\n",
    "In the `accidents.csv` file, we found that there was too much data accidents of severity 2 and three recorded, leading to nearly unreadable graphs and an unusually high accuracy.  As a result, a method was created to ensure the number of all accidents was roughly even across all severities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ftrs(X, y, dimensions=2, cmap=\"viridis\"):\n",
    "    components = PCA(n_components=(dimensions)).fit(X).transform(X)\n",
    "    if dimensions == 2:\n",
    "        fig = plt.figure().add_subplot(111)\n",
    "        scatter = fig.scatter(components[:, 0], components[:, 1], c=y, cmap=cmap)\n",
    "    else:\n",
    "        fig = plt.figure().add_subplot(111, projection=\"3d\")\n",
    "        scatter = fig.scatter(components[:, 0], components[:, 1], components[:, 2], c=y, cmap=cmap)\n",
    "    \n",
    "    plt.colorbar(scatter, ax=fig, ticks=list(np.unique(y)))\n",
    "    plt.show()\n",
    "\n",
    "def dataframe_from_csv(file_name, exclude_cols):\n",
    "    cols = list(pd.read_csv(f\"{file_name}.csv\", nrows=1))\n",
    "\n",
    "    return pd.read_csv(f\"{file_name}.csv\", usecols=[a for a in cols if a not in exclude_cols])\n",
    "\n",
    "def get_accuracy(y_test, y_pred, use_np_mean=False):\n",
    "    if use_np_mean:\n",
    "        accuracy = np.mean(y_test == y_pred)\n",
    "    else:\n",
    "        accuracy = np.dot(y_test, y_pred) / (la.norm(y_test) * la.norm(y_pred))\n",
    "    \n",
    "    return float(f\"{accuracy * 100:.3f}\")\n",
    "\n",
    "def cull_data(dataset, features, percent_of_even_data_to_use=1):\n",
    "    accident_data = data_frames[dataset][features].dropna().values\n",
    "    np.random.shuffle(accident_data)\n",
    "    \n",
    "    unique_labels, unique_label_counts = np.unique(accident_data[:, -1], return_counts = True)\n",
    "    returning_accident_data = accident_data[accident_data[:, -1] == unique_labels[0]][:int(np.min(unique_label_counts) * percent_of_even_data_to_use), :]\n",
    "    for l in range(1, len(unique_labels)):\n",
    "        returning_accident_data = np.vstack((returning_accident_data, accident_data[accident_data[:, -1] == unique_labels[l]][:int(np.min(unique_label_counts) * percent_of_even_data_to_use), :]))\n",
    "    \n",
    "    np.random.shuffle(returning_accident_data)\n",
    "    return returning_accident_data\n",
    "\n",
    "def mult_list(val_list):\n",
    "    product = len(val_list[0])\n",
    "\n",
    "    for val in val_list:\n",
    "        product *= len(val_list)\n",
    "\n",
    "    return product\n",
    "\n",
    "def count_iters(params):\n",
    "    param_lens = [len(val) for _, val in params.items()]\n",
    "    return sum(param_lens) + mult_list(param_lens)\n",
    "    \n",
    "\n",
    "def custom_cv(estimators, X, y, params_list, test_size=0.3, timed=True, verbose=False):\n",
    "    if timed: start_time = time()\n",
    "\n",
    "    ret_dict = {}\n",
    "    X_train, X_test, y_train, y_test = tts(X, y, test_size=test_size)\n",
    "\n",
    "    if len(estimators) != len(params_list):\n",
    "        print(\"The number of estimators and corresponding parameters does not match\")\n",
    "        return\n",
    "        \n",
    "    for a in range(len(estimators)):\n",
    "        estimator_name = estimators[a].__class__.__name__\n",
    "        if timed: individual_time = time()\n",
    "        pipe = Pipeline([(\"scaler\", SS()), (\"gscv\", GSCV(estimators[a], params_list[a], verbose=1 if verbose else 0))])\n",
    "        pipe.fit(X_train, y_train)\n",
    "\n",
    "        ret_dict[estimator_name] = {\n",
    "            \"best_accuracy\": get_accuracy(y_test, pipe.predict(X_test)),\n",
    "            # \"best_estimator\": pipe.named_steps[\"gscv\"].best_estimator_,\n",
    "            \"best_params\": pipe.named_steps[\"gscv\"].best_params_,\n",
    "            \"best_score\": pipe.named_steps[\"gscv\"].best_score_,\n",
    "        }\n",
    "\n",
    "        if timed: ret_dict[estimator_name][\"fit_time\"] = time() - individual_time\n",
    "        if verbose and timed: print(f\"{estimator_name} fit time: {ret_dict[estimator_name]['fit_time']:.3f} seconds\")\n",
    "\n",
    "    if timed: ret_dict[\"total_time\"] = time() - start_time\n",
    "    if verbose and timed: print(f\"Total Cross Validation fit time: {ret_dict['total_time'] / 60:.3f} minutes\")\n",
    "\n",
    "    return ret_dict\n",
    "\n",
    "def print_cv_results(cust_cv_results, precision=3):\n",
    "    for key, results_dict in cust_cv_results.items():\n",
    "        if not isinstance(results_dict, dict):\n",
    "            continue\n",
    "            \n",
    "        print(f\"Showing results of Grid Search and Cross Validation for: {key}\")\n",
    "        print(f\"\\tBest Params: {results_dict['best_params']}\")\n",
    "        print(f\"\\tBest Score: {results_dict['best_score']:.{precision}f}\")\n",
    "        print(f\"\\tFinal {key} Accuracy: {results_dict['best_accuracy']:.{precision}f}%\")\n",
    "        try:\n",
    "            print(f\"\\t{key} Fit Time: {results_dict['fit_time']:.{precision}f} seconds\\n\")\n",
    "        except KeyError:\n",
    "            print()\n",
    "\n",
    "    try:\n",
    "        print(f\"Total time to fit all classifiers: {cust_cv_results['total_time'] / 60:.{precision}f} minutes\")\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downloading of the Data Files**\n",
    "\n",
    "We used dropbox to store the CSV files and used their urls to load them into pandas Dataframes using our custom method `dataframe_from_csv`.\n",
    "To save load time, if the method first checks if the datasets are already downloading before attempting to download from the dropbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vehicles.csv\n",
      "Loading casualties.csv\n",
      "Loading accidents.csv\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Download data files\n",
    "urls = {\n",
    "    \"vehicles\": \"https://www.dropbox.com/scl/fi/rfywugpl0vxo5mc5b7uy7/Vehicles0514.csv?rlkey=v4yygd6hc96ejfm9nt1fvadz9&dl=0\",\n",
    "    \"casualties\": \"https://www.dropbox.com/scl/fi/o1ljw70bzrwmx0x8etifq/Casualties0514.csv?rlkey=iwyg1ergtazhl6mgwqk78xn5s&dl=0\",\n",
    "    \"accidents\": \"https://www.dropbox.com/scl/fi/7enn6tyaavc8ch8hlib0f/Accidents0514.csv?rlkey=u316i9rln87722m1fefzfp5ba&dl=0\",\n",
    "    \"data-guide\": \"https://www.dropbox.com/scl/fi/amogx0ugusmivneq6ardz/Road-Accident-Safety-Data-Guide.xls?rlkey=rnkxrf6eqjer67x2lv99tzvvv&dl=0\"\n",
    "}\n",
    "\n",
    "data_frames = {}\n",
    "\n",
    "# pd.read_excel(urls[\"data-guide\"], sheet_name=\"Export Variables\", engine=\"xlrd\")\n",
    "\n",
    "exclude_columns = [\"Accident_Index\", \"LSOA_of_Accident_Location\"]\n",
    "for file_name in list(urls.keys())[:-1]:\n",
    "    print(f\"Loading {file_name}.csv\")\n",
    "    if path.exists(f\"{file_name}.csv\"):\n",
    "        data_frames[file_name] = dataframe_from_csv(file_name, exclude_columns)\n",
    "        continue\n",
    "        \n",
    "    direct_url = urls[file_name].replace(\"&dl=0\", \"&dl=1\")\n",
    "    response = requests.get(direct_url)\n",
    "\n",
    "    with open(f\"{file_name}.csv\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "        print(f\"Wrote {file_name}.csv\")\n",
    "\n",
    "    data_frames[file_name] = dataframe_from_csv(file_name, exclude_columns)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Question: How does the weather impact the serverity of the accident?\n",
    "accident_data = cull_data(\n",
    "    \"accidents\",\n",
    "    [\"Weather_Conditions\", \"Road_Surface_Conditions\", \"Special_Conditions_at_Site\", \"Carriageway_Hazards\", \"Accident_Severity\"], \n",
    "    0.02\n",
    ")\n",
    "\n",
    "X = accident_data[:, :-1]\n",
    "y = accident_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ftrs(X, y, dimensions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(accident_data[:, 2], accident_data[:, 3], c=y, cmap=\"viridis\", alpha=0.75)\n",
    "plt.xlabel(\"Special Conditions\")\n",
    "plt.ylabel(\"Carriageway hazards\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(accident_data[:, 0], accident_data[:, 1], c=y, cmap=\"viridis\", alpha=0.75)\n",
    "plt.xlabel(\"Weather Conditions\")\n",
    "plt.ylabel(\"Road Conditions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "We approached testing each classifier on question 1 (Can various details about the weather be used to accuractely predict the severity of a crash?) by using Grid Search combined with Cross Validation on our culled dataset to obtain the best parameters for each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "SVC fit time: 4.119 seconds\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "RandomForestClassifier fit time: 6.025 seconds\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "KNeighborsClassifier fit time: 0.283 seconds\n",
      "Total Cross Validation fit time: 0.174 minutes\n",
      "Showing results of Grid Search and Cross Validation for: SVC\n",
      "\tBest Params: {'C': 0.1, 'gamma': 10, 'kernel': 'rbf'}\n",
      "\tBest Score: 0.3594\n",
      "\tFinal SVC Accuracy: 87.4530%\n",
      "\tSVC Fit Time: 4.1194 seconds\n",
      "\n",
      "Showing results of Grid Search and Cross Validation for: RandomForestClassifier\n",
      "\tBest Params: {'n_estimators': 1000}\n",
      "\tBest Score: 0.3616\n",
      "\tFinal RandomForestClassifier Accuracy: 87.4270%\n",
      "\tRandomForestClassifier Fit Time: 6.0245 seconds\n",
      "\n",
      "Showing results of Grid Search and Cross Validation for: KNeighborsClassifier\n",
      "\tBest Params: {'n_neighbors': 80}\n",
      "\tBest Score: 0.3571\n",
      "\tFinal KNeighborsClassifier Accuracy: 87.4750%\n",
      "\tKNeighborsClassifier Fit Time: 0.2831 seconds\n",
      "\n",
      "Total time to fit all classifiers: 0.1738 minutes\n"
     ]
    }
   ],
   "source": [
    "svc_params = {\n",
    "    \"kernel\": [\"linear\", \"rbf\"],\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"gamma\": [0.001, 0.01, 0.1, 1, 10],\n",
    "}\n",
    "rfc_params = {\n",
    "    \"n_estimators\": [1, 10, 100, 1000]\n",
    "}\n",
    "knn_params = {\n",
    "    \"n_neighbors\": [1, 2, 4, 8, 10, 20, 40, 80]\n",
    "}\n",
    "\n",
    "results = custom_cv([SVC(), RFC(), KNN()], X, y, params_list=[svc_params, rfc_params, knn_params], verbose=True)\n",
    "print_cv_results(results, precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM accuracy = 89.568%\n",
      "Best SVM parameters = {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best SVM score = 0.359\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best SVM accuracy = {results['best_accuracy']:.3f}%\")\n",
    "print(\"Best SVM parameters =\", results['best_params'])\n",
    "print(f\"Best SVM score = {results['best_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_forest_classifier(X, y):\n",
    "    \n",
    "    rfc_params = {\n",
    "        \"n_estimators\": [10, 100, 1000],\n",
    "    }\n",
    "    rfc_results = custom_cv(RFC(), X, y, params = rfc_params, verbose = True);\n",
    "    \n",
    "    # print(f\"Best RFC accuracy = {rfc_results['best_accuracy']:.3f}%\")\n",
    "    print(\"Best RFC parameters = \", rfc_results['best_params'])\n",
    "    print(f\"Best RFC score = {rfc_results['best_score']:.3f}%\")\n",
    "    \n",
    "    return rfc_results['best_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Total Cross Validation fit time: 0.088 minutes\n",
      "Best RFC parameters =  {'n_estimators': 100}\n",
      "Best RFC score = 0.340%\n",
      "Accuracy of Random Forest Classification: 90.015%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of Random Forest Classification: {run_random_forest_classifier(X, y)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn_classifier(X, y):\n",
    "    knn_params = {\n",
    "        \"n_neighbors\": [1, 2, 4, 8, 10, 20, 40, 80],\n",
    "    }\n",
    "    knn_results = custom_cv(KNeighborsClassifier(), X, y, params = knn_params, verbose = True)\n",
    "    \n",
    "    # print(f\"Best KNN accuracy = {knn_results['best_accuracy']:.3f}%\")\n",
    "    print(\"Best KNN parameters = \", knn_results['best_params'])\n",
    "    print(f\"Best KNN score = {knn_results['best_score']:.3f}%\")\n",
    "    \n",
    "    return knn_results['best_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Total Cross Validation fit time: 0.005 minutes\n",
      "Best KNN parameters =  {'n_neighbors': 40}\n",
      "Best KNN score = 0.360%\n",
      "Accuracy of K Nearest Neighbors Classification: 87.728%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of K Nearest Neighbors Classification: {run_knn_classifier(X, y)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
